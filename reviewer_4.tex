\section{Reviewer 4}
\label{sec:reviewer_4}

\textcolor{blue}{
The Authors present an interesting and original research on a numerical
method for simulating contact problems. The method can resolve corner
case scenarios that are known to be difficult in conventional multibody
solvers, hence it is very promising in the framework of robotics, that
always strive for maximum robustness and stability. The transformation
dual-vs-primal is an interesting strategy that allows the simulation of
near-rigid FEA structures in NSCD, something that was always
challenging.
Some comments that the Authors can address:
}
\vspace{5mm}

\textcolor{blue}{R4-Q1: page 2: "the convex approximation introduces a gliding
artifact at a distance proportional to the time step size and to the sliding
velocity" ... I would recall: *and to the friction coefficient $\mu$ *. Later
(ex. pag.6) this is mentioned. The proportionality with the friction coefficient
means that such artifact can be irrelevant for problems with lubricated contacts
as in many mechanisms, but still relevant for sticky materials, ex. rubber etc.
like in robot grippers etc. (maybe worth mentioning this, as the paper is
involving robotic \& manipulation)}

Thank you for this very useful remark. We added text in the revised manuscript
highlighting this observation.

\vspace{5mm}

\textcolor{blue}{R4-Q2: pag.2: "The multi-physics simulation package Chrono implements a
variant of the PGS method [...] the solver exhibits low convergence
rates.". True, but that PGS is not the only solver available in that
simulation library: additional methods based on Nesterov,
Barzilai-Borwein accelerations and ADMM have been introduced with the
aim of better convergence.}

We thank the reviewer for pointing this out. We updated the manuscript with
appropriate references to these methods. These references are excellent, showing
the scalability of these methods to millions of objects, typically for granular
flow applications. Unlike our work, Chrono implements first order methods, which
usually exhibit slow convergence though as demonstrated in these references, are
amenable to massively parallel architectures. Our work however is focused on a
highly accurate second order solver allowing tight coupling of the unknowns as
required for the very sensitive manipulation applications we target.

\vspace{5mm}

\textcolor{blue}{R4-Q3: pag.4: "K and D are constant, diagonal, and positive
definite matrices.". Are there assumptions on K and D being symmetric in your
implementation? In many FEA nonlinear problems these are not symmetric, for
example. Can this have an impact on numerical performances? Comment on this,
please.}

Yes. Actually, we split the forces term $\mf{k}$ into $\mf{k}_1$ and $\mf{k}_2$
precisely to ensure that the stiffness and damping matrices are symmetric
positive definite. This then allows us to obtain an SPD approximation $\mf{A}$ of
the gradient $\partial \mf{m}/\partial \mf{v}$. We highlighted edited text in
Section II.D making specific mentions to the important case of joint spring
dampers, for which $\mf{K}$ and $\mf{D}$ are positive diagonal matrices.
Regarding finite elements modeling, we are currently working on a new
publication that incorporates our new SAP solver within a FEM framework. In this
new work, we essentially restrict to materials whose internal stress comes from
an internal elastic energy. Significantly more details will be provided in that
piece of work. We updated the text in Section VII to briefly mention this
discussion.

\vspace{5mm}

\textcolor{blue}{R4-Q4: pag.7: on line search: have you considered to use an
inexact "buffered" line search like Grippo-Lampariello-Lucidi (GLL)? This could
speed up line search where Armijo or other strategies can be too conservative
during zones of frequent constraint transitions.}

We thank the reviewer for this suggestion, we were not familiar with this line
search strategy. We studied the method in detail, implemented it in
our code and re-ran our benchmarking cases. We verified the correctness of the
method in several ways:
\begin{itemize}
    \item As proved in the original GLL work \cite{bib:grippo1986nonmonotone},
    while the method allows for non-monotonic convergence, the sequence
    $\{\max_{0\leq j \leq m(k)}\ell_{k-j}\}$ is nonincreasing (see Eq. (5) in
    \cite{bib:grippo1986nonmonotone}). We verified this property in all of our
    tests.
    \item Even if slow, convergence is guaranteed. We verified that the method
    does converge if we allow a very large number of Newton iterations. However,
    we found we had to increase this limit beyond what is practical in terms of
    performance.
    \item GLL reduces to Armijo's strategy if no history is tracked ($M=0$).
\end{itemize}

In summary, the GLL line-search performed very badly for our particular
formulation. We believe the reason is that because our problem is convex, the most
performant strategy will always strive for monotonic convergence. We observed that
our exact line search and our backtracking line search in the original
submission perform the best. We found our exact line search to be the most robust
method. The backtracking line-search can in some situations slow down
convergence given that it effectively applies a non-optimal over relaxation.

As an example, we run the \emph{Clutter} case from Section VI.C in the paper,
where a number of bodies are dropped inside a bin. For both our backtracking
line search and GLL, we used $\rho=0.8$ (Section IV.C) and Armijo's parameter
$c=10^{-4}$. GLL as presented in \cite{bib:grippo1986nonmonotone} has two
additional parameters; $N$ is the number of regular Armijo's line searches
performed before the algorithm switches to GLL criterion, and $M$ is the size of the cost
history tracked by GLL. See \cite{bib:grippo1986nonmonotone} for details. $M=0$
corresponds to the traditional line search with Armijo's criterion. 

We tried a wide range of these parameters as suggested in
\cite{bib:grippo1986nonmonotone}. In all cases, we obtained much worse
performance when compared to our methods. We allowed SAP to perform a maximum of
5000 Newton iterations to allow GLL to converge. Table
\ref{tab:gll_test} summarizes wall-clock time for different line search
strategies used to simulate 10 seconds of the clutter case (1000 time steps with
$\delta t = 0.01\text{~s}$). In this table, the \emph{Exact} and
\emph{Backtracking} rows refer to the methods in our paper, \emph{Armijo} refers
to GLL method when $M=0$. For these cases, GLL uses the regular Armijo's criterion
on the first iteration ($N=1$). We observed in these and other cases that GLL
requires a significantly larger number of iterations to converge, and therefore
the longer wall-clock time in Table \ref{tab:gll_test}. Entries with
\emph{crosses} refer to cases for which GLL did not converge within the maximum
number of Newton iterations allowed, 5000. For this particular example, the
backtracking line search exhibits better performance than the exact line search.
However as we mentioned before, the exact line search is more robust for a wider
range of problems.

\begin{table}[h!]
    \centering
\begin{tabular}{|l||r|r|r|r|}
    \hline
    Line Search / \# Objects & 20   & 40   & 80 & 160 \\
    \hline
    Exact                 & 0.54 & 1.84 & 14.7                  & 253 \\
    Backtracking          & 0.54 & 1.87 & 15.6                  & 199 \\
    Armijo (GLL, M=0)     & 1.06 & 4.05 & 27.3                  & x                       \\
    GLL (N=1, M=2)        & 2.71 & 15.9 & x & x                       \\
    GLL (N=1, M=4)        & 7.1  & 40.5 & x & x \\
    \hline
\end{tabular}
\caption{Total wall-clock time in seconds.}
\label{tab:gll_test}
\end{table}

It should be emphasized that these results are specific to our convex
formulation of contact. The GLL method has shown better performance for other
optimization problems.

\vspace{5mm}

\textcolor{blue}{R4-Q5: pag.7: "supernodal Cholesky factorization" ... this
implies that H is Hermitian, but in some FEA problems the D and K matrices might
be non-symmetric, thus H as well, correct? How do you deal with this, if so? Can
you comment on this? }

Supernodal ideas generalize to LU factorization. However, it is a requirement of
the formulation for the stiffness and damping matrices that are included in the
linear dynamics matrix $\mf{A}$ to be symmetric positive definite. We discussed
this in the answer to R4-Q3. We provided two examples: joint spring and dampers,
which we include in term $\mf{k}_1$, and simulation of deformable solids for
which stresses stem from an internal elastic energy. However, modeling
of deformable objects with frictional contact will be discussed in depth in our
next publication. Please see highlighted text labeled as R4-Q3 in the revised
manuscript.

\vspace{5mm}

\textcolor{blue}{R4-Q6: pag.8, bottom: "...we form the approximation [....].
Using this approximation, we estimate the frequency of the contact dynamics...".
This is a smart idea, although I have a counterexample: suppose you have two
very light particles in contact, but both of them are welded to two very heavy
bodies via two joints: the simplified evaluation of the Delassus operator would
underestimate the contact masses in the constraint metric. If this is the case,
please add a comment on the practical limitation of this simplified Delassus
formula, mentioning a real example like the one I wrote here.}

This is an excellent question, thank you. This particular case mentioned here is
not problematic because we are using joint coordinates. Let's call the two heavy
bodies H1 and H2, and for simplicity, assume they are free. Let's refer to the
light particle welded to H1 as L1 and to the light particle welded to H2 as L2.
In joint coordinates, there will be two trees: t1 formed by L1 welded to H1 and
t2 formed by L2 welded to H2. Therefore the mass matrix for each tree will be
dominated by the mass of the heavy body and the Delassus approximation works
as desired in this case.

However, as the reviewer pointed out, we can still come up with a
counterexample. Consider a stack of books on a table, in particular the one book
at the bottom of the stack in contact with the table. In the \emph{near-rigid}
regime, our approximation will estimate a stiffness based solely on the mass of
this one book. However, the normal force on this book will be the result of the
accumulated weight of all other books on top of it. In this case, we will
underestimate the required compliance and we might need user intervention. 
If we encounter such a case, we simply set $\beta=0$ (which means
the stiffness is not bounded) and set the stiffness to a value that allows the
book at the bottom to support the entire stack.

The updated manuscript mentions this case in the \emph{Limitations} section.

\vspace{5mm}
\textcolor{blue}{R4-Q7: pag. 12: for scalability, you tested up to hundreds of
bodies. Do you think this approach (with the SAP solver, I mean) can scale up to
hundreds of thousands of bodies or millions? Are there limitations? Is it more
practical for "low contact density" scenarios like robotics, or also for "high
contact density" scenarios like granular flows, or both?}

The scalability of SAP, like any second-order optimization method, depends on
the complexity of solving the Newton system. For fully dense problems,
direct methods have $\mathcal{O}(n^3)$ complexity, where $n$
denotes the number of variables.  For sparse problems, improved bounds can be
stated in terms of \emph{tree-width} $d$, a complexity measure defined by the
\cite{chordal-extensions} of the linear system matrix.

We see no reason that SAP could not be applied to millions of bodies if
tree-width $d$ is small.  Further, when $d$ is large, SAP can be modified to improve
scalability.  Specifically, we can approximately solve the Newton system using
the conjugate-gradient (CG) method, which is widely used in large-scale
optimization.  Note that if we terminate CG after one-iteration, SAP reduces to
gradient descent, i.e., a first-order optimization algorithm. 

Note that the  per-iteration complexity of SAP is the same
for interior-point methods (IPMs).  Our computational results show the per-iteration
complexity is comparable to Gurobi, a commercial implementation of an IPM.

Recently, we tested the scalability of SAP for high contact density problems,
though with a small $d$. That is, we performed a grid study with our most recent
contact model that leads to thousands of contact pairs. Still, not all objects
are in contact with each other and therefore SAP achieves almost linear
convergence with the number of contact constraints (an exponent about $n\sim1.3$
to be precise). Details of this scalability study are provided in
\cite{bib:masterjohn2021discrete}.

We added text at the end of Section IV.D and in Section VIII on Limitations.

